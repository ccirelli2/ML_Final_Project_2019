rm(list=ls())
library(boot)
library(caret)
# DATA  Convert sex, cp, fbs, slope, exang, ca and thal to categorical variables.
data.cat             = hr_data
# DATA (note we use the entire dataset for LOOCV)
hr_data = read.csv('/home/ccirelli2/Desktop/GSU/2019_Spring/ML_Course/HW/HW2/HeartData.csv')
# DATA  Convert sex, cp, fbs, slope, exang, ca and thal to categorical variables.
data.cat             = hr_data
data.cat$sex          = factor(data.cat$sex)
data.cat$cp          = factor(data.cat$cp)
data.cat$fbs         = factor(data.cat$fbs)
data.cat$slope       = factor(data.cat$slope)
data.cat$exang       = factor(data.cat$exang)
data.cat$ca          = factor(data.cat$ca)
data.cat$thal        = factor(data.cat$thal)
data_ctrl = trainControl(method = 'cv', number = 10)
data_ctrl = trainControl(method = 'cv', number = 10, verboseIter = TRUE)
?verboseIter
?verboseIter
# Step3:  Examine Model Predictions
lr.m1.cv
# Step2:  Fit Model and pass control parameters to model
lr.m1.cv =        train(num ~ age + sex + cp + trestbps + chol + fbs + restecg + thalach + exang + oldpeak + slope + ca + thal, # model to fit
data = data.cat,                                                       # data
method = 'glm',                                                        # general linear model
family = 'binomial',                                                   # binomial for logistic regression
trControl = data_ctrl                                                  # pass training control parameters.
)
# Step3:  Examine Model Predictions
lr.m1.cv
lr.m1.cv$finalModel
# Step5:  Examine Model Predictions (R2) For Each Fold
lr.m1.cv$resample
plot(lr.m1.cv$resample$RMSE)
plot(lr.m1.cv$resample$RMSE, type='bar')
barplot(lr.m1.cv$resample$RMSE)
barplot(lr.m1.cv$resample$RMSE, nams.arg=c(1,2,3,4,5,6,7,8,9,10))
barplot(lr.m1.cv$resample$RMSE, nams.arg=c(1,2,3,4,5,6,7,8,9,10))
barplot(lr.m1.cv$resample$RMSE, nams.arg=c(1,2,3,4,5,6,7,8,9,10))
plot(lr.m1.cv$resample$RMSE, type='bar')
plot(lr.m1.cv$resample$Rsquared, type ='bar')
plot(lr.m1.cv$resample$Rsquared)
type ='bar'
type ='bar'
plot(lr.m1.cv$resample$Rsquared, type ='bar')
# Step5:  Examine Model Predictions (R2) For Each Fold
lr.m1.cv$Resample
# Step4:  Investigate Final Model
lr.m1.cv$finalModel
lr.m1.cv
lr.m1.cv$bestTune
lr.m1.cv$finalModel$R
mean(lr.m1.cv$resample$Rsquared)
# Step4:  Investigate Final Model
lr.m1.cv$finalModel
# Step5:  Examine Model Predictions (R2) For Each Fold
lr.m1.cv$Resample
# Step5:  Examine Model Predictions (R2) For Each Fold
lr.m1.cv$Resample
# Step2:  Fit Model and pass control parameters to model
lda.m1.cv =        train(num ~ age + sex + cp + trestbps + chol + fbs + restecg + thalach + exang + oldpeak + slope + ca + thal, # model to fit
data = data.cat,                                                       # data
method = 'lda',                                                        # general linear model
trControl = data_ctrl                                                  # pass training control parameters.
)
# Step2:  Fit Model and pass control parameters to model
data_ctrl = trainControl(method = 'cv', number = 10, verboseIter = TRUE)
lda.m1.cv =             train(num ~ age + sex + cp + trestbps + chol + fbs + restecg + thalach + exang + oldpeak + slope + ca + thal, # model to fit
data = data.cat,                                                       # data
method = "lda",                                                        # general linear model
trControl = data_ctrl                                                  # pass training control parameters.
)
# Step2:  Fit Model and pass control parameters to model
data_ctrl = trainControl(method = 'cv', number = 10)
lda.m1.cv =             train(num ~ age + sex + cp + trestbps + chol + fbs + restecg + thalach + exang + oldpeak + slope + ca + thal, # model to fit
data = data.cat,                                                       # data
method = "lda",                                                        # general linear model
trControl = data_ctrl                                                  # pass training control parameters.
)
# Step2:  Fit Model and pass control parameters to model
data_ctrl = trainControl(method = 'cv')
lda.m1.cv =             train(num ~ age + sex + cp + trestbps + chol + fbs + restecg + thalach + exang + oldpeak + slope + ca + thal, # model to fit
data = data.cat,                                                       # data
method = "lda",                                                        # general linear model
trControl = data_ctrl                                                  # pass training control parameters.
)
?lda
# Step2:  Fit Model and pass control parameters to model
lda.m1.cv =             lda(num ~ age + sex + cp + trestbps + chol + fbs + restecg + thalach + exang + oldpeak + slope + ca + thal, # model to fit
data = data.cat,                                                       # data
CV = TRUE)                                                             # general linear model
lda.m1.cv
summary(lda.m1.cv)
lda.m1.cv$terms
lda.m1.cv$posterior
lda.m1.cv$call
lda.m1.cv$xlevels
lda.m1.cv$class
# Step1:  Set up training control
data_ctrl = trainControl(method = 'cv', number = 10, verboseIter = TRUE)
# Step2:  Fit Model and pass control parameters to model
lr.m1.cv =        train(num ~ age + sex + cp + trestbps + chol + fbs + restecg + thalach + exang + oldpeak + slope + ca + thal, # model to fit
data = data.cat,                                                       # data
method = 'lda',                                                        # general linear model
family = 'binomial',                                                   # binomial for logistic regression
trControl = data_ctrl                                                  # pass training control parameters.
)
# Step2:  Fit Model and pass control parameters to model
lda.m1.cv =        train(num ~ age + sex + cp + trestbps + chol + fbs + restecg + thalach + exang + oldpeak + slope + ca + thal, # model to fit
data = data.cat,                                                       # data
method = 'lda',                                                        # general linear model
family = 'binomial',                                                   # binomial for logistic regression
trControl = data_ctrl                                                  # pass training control parameters.
)
lda.m1.cv
# Step2:  Fit Model and pass control parameters to model
lda.m1.cv =        train(num ~ age + sex + cp + trestbps + chol + fbs + restecg + thalach + exang + oldpeak + slope + ca + thal, # model to fit
data = data.cat,                                                       # data
method = 'lda',                                                        # general linear model
trControl = data_ctrl                                                  # pass training control parameters.
)
lda.m1.cv
# Step2:  Fit Model and pass control parameters to model
lda.m1.cv =        train(num ~ age + sex + cp + trestbps + chol + fbs + restecg + thalach + exang + oldpeak + slope + ca + thal, # model to fit
data = data.cat,                                                       # data
method = 'nd',                                                        # general linear model
trControl = data_ctrl                                                  # pass training control parameters.
)
# Step1:  Set up training control
data_ctrl = trainControl(method = 'boot', number = 10, verboseIter = TRUE)
# Step2:  Fit Model and pass control parameters to model
lda.m1.cv =        train(num ~ age + sex + cp + trestbps + chol + fbs + restecg + thalach + exang + oldpeak + slope + ca + thal, # model to fit
data = data.cat,                                                       # data
method = 'lda',                                                        # general linear model
trControl = data_ctrl                                                  # pass training control parameters.
)
# Step1:  Set up training control
data_ctrl = trainControl(method = 'cv', number = 10, verboseIter = TRUE)
library('lda')
library(lda)
library(MASS)
# Step2:  Fit Model and pass control parameters to model
lda.m1.cv =        train(num ~ age + sex + cp + trestbps + chol + fbs + restecg + thalach + exang + oldpeak + slope + ca + thal, # model to fit
data = data.cat,                                                       # data
method = 'lda',                                                        # general linear model
trControl = data_ctrl                                                  # pass training control parameters.
)
# Step2:  Fit Model and pass control parameters to model
lda.m1.cv =        train(num ~ age + sex + cp + trestbps + chol + fbs + restecg + thalach + exang + oldpeak + slope + ca + thal, # model to fit
data = data.cat,                                                       # data
method = 'lda',                                                        # general linear model
trControl = trainControl('cv')                                                  # pass training control parameters.
)
lda.m1.cv.fit
library(caret)
library('mlbench')
library(mlbench)
install.packages("mlbench")
mlbench
library(mlbench)
# Step1:  Set up training control
kfoldcv = trainControl(method="cv", number=10)
performance_metric = 'Accuracy'
lda.data = train(train(num ~., data=hr_data, method="lda", metric=performance_metric trControl=kfoldcv)
lda.data = train(train(num ~., data=hr_data, method="lda", metric=performance_metric, trControl = kfoldcv)
lda.data = train(num ~., data=hr_data, method="lda", metric=performance_metric, trControl = kfoldcv)
lda.data = train(num~., data=hr_data, method="lda", metric=performance_metric, trControl = kfoldcv)
data_ctrl = trainControl(method = 'cv', number = 10, verboseIter = TRUE)
lda.m1.cv =        train(num ~., # model to fit
data = data.cat,                                                       # data
method = 'lda',                                                        # general linear model
family = 'binomial',                                                   # binomial for logistic regression
trControl = data_ctrl                                                  # pass training control parameters.
)
lda.m1.cv =        train(num ~., # model to fit
data = data.cat,                                                       # data
method = 'lda',                                                        # general linear model
family = 'binomial',                                                   # binomial for logistic regression
trControl = data_ctrl                                                  # pass training control parameters.
)
lda.m1.cv =        train(num ~., # model to fit
data = data.cat,                                                       # data
method = 'glm',                                                        # general linear model
family = 'binomial',                                                   # binomial for logistic regression
trControl = data_ctrl                                                  # pass training control parameters.
)
lda.m1.cv =        train(num ~., # model to fit
data = data.cat,                                                       # data
method = 'glm',                                                        # general linear model
family = 'binomial',                                                   # binomial for logistic regression
trControl = data_ctrl                                                  # pass training control parameters.
)
lda.m1.cv =        train(num ~., # model to fit
data = data.cat,                                                       # data
method = 'qda',                                                        # general linear model
family = 'binomial',                                                   # binomial for logistic regression
trControl = data_ctrl                                                  # pass training control parameters.
)
data_ctrl = trainControl(method = 'cv', number = 10, classProbs = TRUE, summaryFunction = twoClassSummary)
lda.m1.cv =        train(data.cat,
# data
method = 'lda',                                                        # general linear model
family = 'binomial',                                                   # binomial for logistic regression
trControl = data_ctrl                                                  # pass training control parameters.
)
lda.m1.cv =        train(data.cat,
# data
method = 'lda',                                                        # general linear model
# binomial for logistic regression
trControl = data_ctrl                                                  # pass training control parameters.
)
x = data.cat[:, -data.cat$num]
x = data.cat[0:length(data.cat$age), -data.cat$num]
head(x)
x = data.cat[0:length(data.cat$age), 0:13]
head(x)
lda.m1.cv =        train(x, y
method = 'lda',                                                        # general linear model
trControl = data_ctrl,                                                  # pass training control parameters.
metric = 'Accuracy'
)
lda.m1.cv =        train(x, y,
method = 'lda',                                                        # general linear model
trControl = data_ctrl,                                                  # pass training control parameters.
metric = 'Accuracy'
)
y = data.cat$num
lda.m1.cv =        train(x, y,
method = 'lda',                                                        # general linear model
trControl = data_ctrl,                                                  # pass training control parameters.
metric = 'Accuracy'
)
x = hr_data[0:length(data.cat$age), 0:13]
y = hr_data$num
lda.m1.cv =        train(x, y,
method = 'lda',                                                        # general linear model
trControl = data_ctrl,                                                  # pass training control parameters.
metric = 'Accuracy'
)
data_ctrl = trainControl(method = 'cv', number = 10, verboseIter = TRUE)
data.cat$num
lda.m1.cv =        train(num ~., # model to fit
data = data.cat,                                                       # data
method = 'lda',                                                        # general linear model
family = 'binomial',                                                   # binomial for logistic regression
trControl = data_ctrl                                                  # pass training control parameters.
)
lda.m1.cv =        train(num ~., # model to fit
data = data.cat,                                                       # data
method = 'qda',                                                        # general linear model
family = 'binomial',                                                   # binomial for logistic regression
trControl = data_ctrl                                                  # pass training control parameters.
)
data.cat$num         = factor(data.cat$num)
data_ctrl = trainControl(method = 'cv', number = 10, verboseIter = TRUE)
lda.m1.cv =        train(num ~., # model to fit
data = data.cat,                                                       # data
method = 'lda',                                                        # general linear model
family = 'binomial',                                                   # binomial for logistic regression
trControl = data_ctrl                                                  # pass training control parameters.
)
data_ctrl = trainControl(method = 'cv', number = 10, verboseIter = TRUE)
lda.m1.cv =        train(num ~., # model to fit
data = data.cat,                                                       # data
method = 'qda',                                                        # general linear model
family = 'binomial',                                                   # binomial for logistic regression
trControl = data_ctrl                                                  # pass training control parameters.
)
# Step4:  Investigate Final Model
lr.m1.cv$finalModel
lda.m1.cv$resample$Accuracy
lda.m1.cv$resample$Accuracy
# Step5:  Examine Model Predictions (R2) For Each Fold
lr.m1.cv$Resample
# Step5:  Examine Model Predictions (R2) For Each Fold
lr.m1.cv$results
lda.m1.cv$results
lqa.m1.cv =        train(num ~., # model to fit
data = data.cat,                                                       # data
method = 'qda',                                                        # general linear model
family = 'binomial',                                                   # binomial for logistic regression
trControl = data_ctrl                                                  # pass training control parameters.
)
qda.m1.cv =        train(num ~., # model to fit
data = data.cat,                                                       # data
method = 'qda',                                                        # general linear model
family = 'binomial',                                                   # binomial for logistic regression
trControl = data_ctrl                                                  # pass training control parameters.
)
lr.m1.cv$results
lda.m1.cv$results
qda.m1.cv$results
# Step1:  Set up training control
data_ctrl = trainControl(method = 'cv', number = 10, verboseIter = TRUE, metric = "Accuracy")
data_ctrl_loocv = trainControl(method = 'LOOCV', number = 10, verboseIter = TRUE)
lr.m1.cv.loocv = train(num ~ age + sex + cp + trestbps + chol + fbs + restecg + thalach + exang + oldpeak + slope + ca + thal, # model to fit
data = data.cat,                                                       # data
method = 'glm',                                                        # general linear model
family = 'binomial',                                                   # binomial for logistic regression
trControl = data_ctrl_loocv                                                  # pass training control parameters.
)
lr.m1.cv.loocv
lda.m1.cv =        train(num ~., # model to fit
data = data.cat,                                                       # data
method = 'lda',                                                        # general linear model
family = 'binomial',                                                   # binomial for logistic regression
trControl = data_ctrl_loocv                                                  # pass training control parameters.
)
lda.m1.cv.loocv =        train(num ~., # model to fit
data = data.cat,                                                       # data
method = 'lda',                                                        # general linear model
family = 'binomial',                                                   # binomial for logistic regression
trControl = data_ctrl_loocv                                                  # pass training control parameters.
)
lda.m1.cv.loocv
qda.m1.cv,loocv =        train(num ~., # model to fit
data = data.cat,                                                       # data
method = 'qda',                                                        # general linear model
family = 'binomial',                                                   # binomial for logistic regression
trControl = data_ctrl_loocv                                                  # pass training control parameters.
)
qda.m1.cv.loocv =        train(num ~., # model to fit
data = data.cat,                                                       # data
method = 'qda',                                                        # general linear model
family = 'binomial',                                                   # binomial for logistic regression
trControl = data_ctrl_loocv                                                  # pass training control parameters.
)
qda.m1.cv.loocv
# Clean Namespace
rm(list = ls())
# LOAD LIBRARIES
library(RMySQL)
# CLEAR NAMESPACE
rm(list = ls())
# LOAD LIBRARIES
library(RMySQL)
# SETUP CONNECTION TO DB
mydb <- dbConnect(RMySQL::MySQL(), user='ccirelli2',
password='Work4starr', dbname='GSU',
host = "127.0.0.1")
# Get List of Tables
dbListTables(mydb)
query1_alldata = dbSendQuery(mydb, '
SELECT
MONTH(pickup_datetime) AS "MONTH",
DAY(pickup_datetime) AS "DAY",
pickup_x,
pickup_y,
dropoff_x,
dropoff_y,
duration
FROM ML_FinProj_GothamCab_Train
WHERE duration != 0
LIMIT 1000')
result_q1 = fetch(query1_alldata, n = -1)
# Query 2:  Average Duration By Month
query2_rel_month_duration = dbSendQuery(mydb, '
SELECT
MONTH(pickup_datetime) AS "MONTH",
ROUND(AVG(duration),0) AS "AVERAGE_DURATION"
FROM GSU.ML_FinProj_GothamCab_Train
GROUP BY MONTH(pickup_datetime)
ORDER BY ROUND(AVG(duration),0);')
result_q2 = fetch(query2_rel_month_duration, n = -1)
barplot(data_q2$AVERAGE_DURATION, names.arg = data_q2$MONTH,
main = "Avg Duration By Month",
xlab = "Month",
ylab = "Duration")
barplot(data_q2$AVERAGE_DURATION, names.arg = result_q2$MONTH,
main = "Avg Duration By Month",
xlab = "Month",
ylab = "Duration")
barplot(result_q2$AVERAGE_DURATION, names.arg = result_q2$MONTH,
main = "Avg Duration By Month",
xlab = "Month",
ylab = "Duration")
# Query 3 - Relationship of Average Duration By Day of Week
query3_rel_day_duration = dbSendQuery(mydb, '
SELECT
DAY(pickup_datetime) AS "DAY",
ROUND(AVG(duration),0) AS "AVERAGE_DURATION"
FROM GSU.ML_FinProj_GothamCab_Train
GROUP BY DAY(pickup_datetime)
ORDER BY DAY(pickup_datetime);')
result_q3 = fetch(query3_rel_day_duration, n = -1)
barplot(result_q3$AVERAGE_DURATION,
names.arg = result_q3$DAY,
main = "Average Duration By Day Of Week",
xlab = "Day",
ylab = "Duration")
test_date = 2012-02-01
test_date = weekdays(as.Date(2012-02-01))
test_date = weekdays(as.Date('2012-02-01'))
test_date
test_date = weekdays(as.Date('2034-01-01'))
test_date
query4_rel_weekday_duration = dbSendQuery(mydb, '
SELECT
Weekday,
ROUND(AVG(duration),0) AS "AVERAGE_DURATION"
FROM GSU.ML_FinProj_GothamCab_Train
GROUP BY Weekday
ORDER BY DAY(pickup_datetime);')
query4_rel_weekday_duration = dbSendQuery(mydb, '
SELECT
Weekday,
ROUND(AVG(duration),0) AS "AVERAGE_DURATION"
FROM GSU.ML_FinProj_GothamCab_Train
GROUP BY Weekday
ORDER BY Weekday;')
result_q4 = fetch(query4_rel_weekday_duration, n = -1)
barplot(result_q3$AVERAGE_DURATION,
names.arg = result_q3$DAY,
main = "Average Duration By Weekday",
xlab = "Weekday",
ylab = "Duration")
barplot(result_q4$AVERAGE_DURATION,
names.arg = result_q4$Weekday,
main = "Average Duration By Weekday",
xlab = "Weekday",
ylab = "Duration")
print(result_q4.head())
print(result_q4)
boxplot(result_q4)
boxplot(result_q1$duration)
result_q1$duration
plot(result_q1$duration)
boxplot(result_q1$duration)
histogram(result_q1$duration)
hist(result_q1$duration)
density(result_q1$duration)
d = density(result_q1$duration)
plot(d)
query5_rel_route_duration = dbSendQuery(mydb, '
SELECT
pickup_x,
pickup_y,
dropoff_x,
dropoff_y,
COUNT(duration) AS "Route Count"
FROM GSU.ML_FinProj_GothamCab_Train
GROUP BY pickup_x, pickup_y, dropoff_x, dropoff_y
ORDER BY COUNT(duration) DESC'
)
# Plot Durations
plot(result_q1$duration)
boxplot(result_q1$duration)
hist(result_q1$duration)
d = density(result_q1$duration)
plot(d)
## CLEAR NAMESPACE________________________________________________________________________
rm(list = ls())
## IMPORT LIBRARIES_______________________________________________________________________
library(lattice)
library(ggplot2)
library(caret)  # used for parameter tuning
## CREATE DATASET_________________________________________________________________________
setwd('/home/ccirelli2/Desktop/GSU/2019_Spring/ML_Course/2019_GSU_ML_Final_Project/Gotham_Cabs/data')
s1.50k.data        = read.csv('sample1_50k.csv')
# Dataset - No Pre-Processing (no)-------------------------------------------------------
s1.50k.nopp        = s1.50k.data[2:11]                                        # index:     [2:11] drops the datetime feature as we have already covered this in this in the derived features
# Dataset - No Pre-Processing (no)-------------------------------------------------------
s1.50k.nopp        = s1.50k.data[2:11]                                        # index:     [2:11] drops the datetime feature as we have already covered this in this in the derived features
set.seed(123)                                                                 # set seed
# Randomize Data
s1.50k.nopp        = s1.50k.nopp[sample(nrow(s1.50k.nopp)),]                  # sample automatically reorders the elements.  We pass the num of rows in orig dataset to sort entire data.
s1.50k.nopp.sample = 0.7 * nrow(s1.50k.nopp)
# Train / Test Split
s1.50k.nopp.train  = s1.50k.nopp[1:s1.50k.nopp.sample, ]                      # define training set as 70% of number of observations
s1.50k.nopp.test   = s1.50k.nopp[s1.50k.nopp.sample : nrow(s1.50k.nopp),]     # test set 1 - nrow(train)
# Dataset - Create Factors From Continous Variables---------------------------------------
s1.50k.pp = s1.50k.nopp
s1.50k.pp$pickup_x     <- factor(s1.50k.pp$pickup_x)
s1.50k.pp$pickup_y   <- factor(s1.50k.pp$pickup_y)
s1.50k.pp$dropoff_x   <- factor(s1.50k.pp$dropoff_x)
s1.50k.pp$dropoff_y   <- factor(s1.50k.pp$dropoff_y)
s1.50k.pp$weekday   <- factor(s1.50k.pp$weekday, order = TRUE)              # ordinal
s1.50k.pp$hour_   <- factor(s1.50k.pp$hour_, order = TRUE)                  # ordinal
s1.50k.pp$day_   <- factor(s1.50k.pp$day_, order = TRUE)                    # ordinal
s1.50k.pp$Month_   <- factor(s1.50k.pp$Month_, order = TRUE)                # ordinal
is.factor(s1.50k.pp$weekday)                                                  # Check if a factor
is.ordered((s1.50k.pp$weekday))                                               # Check if ordered
# Train / Test Split
s1.50k.pp        = s1.50k.pp[sample(nrow(s1.50k.pp)),]                  # sample automatically reorders the elements.
# Within the index of our dataframe, we pass sample.   Within sample() we pass the total num of rows.
s1.50k.pp.sample = 0.7 * nrow(s1.50k.pp)                                # Sample = 70% of all observations.
# Within the index of our dataframe, we pass sample.   Within sample() we pass the total num of rows.
s1.50k.pp.sample = 0.7 * nrow(s1.50k.pp)                                # Sample = 70% of all observations.
s1.50k.pp.train  = s1.50k.pp[1:s1.50k.pp.sample, ]                      # define training set as 1 to (.7 * total of number of observations)
s1.50k.pp.test   = s1.50k.pp[s1.50k.pp.sample : nrow(s1.50k.pp),]     # test set 1 - nrow(train)
# Train Model 7:  Stepwise Selection Using Processed Data
train.control = trainControl(method = 'cv', number = 10)
m7.backward = train(duration ~ ., data = s1.50k.pp.train,
method = 'leapBackward',
tuneGrid = data.frame(nvmax = 1:7),
trControl = train.control)
m7.backward$results
summary(m7.$finalModel)
# Duration vs Distance
m1.lr = lm(duration ~ distance, data = s1.50k.nopp.train)
summary(m1.lr)
m1.lr.predict = predict(m1.lr, s1.50k.nopp.test)
m1.mse = sqrt(sum(s1.50k.nopp.test$duration - m1.lr.predict)^2) # Calculate Square Root of Residual Sum of Squared Errors.
m1.mse
# Train Model 6:  Forward Selection
m6.forward = train(duration ~ ., data = s1.50k.nopp.train,
method = 'leapForward',
tuneGrid = data.frame(nvmax = 1:7),
trControl = train.control)
m6.forward$results
summary(m6.forward$finalModel)
