# Calculate Number of Training Observations
train_nrows_50k  = (nrow(s1.50k.nolimits)  * .7)
train_nrows_100k = (nrow(s2.100k.nolimits)   * .7)
train_nrows_250k = (nrow(s3.250k.nolimits)   * .7)
# Train
s1.train = s1.50k.nolimits_ran[1:   train_nrows_50k, ]
s2.train = s2.100k.nolimits_ran[1:  train_nrows_100k, ]
s3.train = s3.250k.nolimits_ran[1:  train_nrows_250k, ]
s4.train = s4.50k.wlimits_ran[1:    train_nrows_50k, ]
s5.train = s5.100k.wlimits_ran[1:   train_nrows_100k, ]
s6.train = s6.250k.wlimits_ran[1:   train_nrows_250k, ]
# Test
s1.test = s1.50k.nolimits_ran[train_nrows_50k:    nrow(s1.50k.nolimits_ran), ] # Index from training to total
s2.test = s2.100k.nolimits_ran[train_nrows_100k:  nrow(s2.100k.nolimits_ran), ]
s3.test = s3.250k.nolimits_ran[train_nrows_250k:  nrow(s3.250k.nolimits_ran), ]
s4.test = s4.50k.wlimits_ran[train_nrows_50k:     nrow(s4.50k.wlimits_ran), ]
s5.test = s5.100k.wlimits_ran[train_nrows_100k:   nrow(s5.100k.wlimits_ran), ]
s6.test = s6.250k.wlimits_ran[train_nrows_250k:   nrow(s6.250k.wlimits_ran), ]
t1     = Sys.time()
m.01     = randomForest(duration ~ ., data=s1.train, ntrees = 10, tuneLength = 5)
m.01.rse = sqrt(m.01$mse)
m.01.rse
print(paste('Random Forest Run Time',Sys.time() - t1))
library(randomForest)
?ranger()
# Test Number of Trees
list.node.size = c()
list.oob.rse = c()
list.test.rse = c()
Count = 1
rf_num_trees = function(data.train, data.test, list.ntrees, list.oob.rse, list.test.rse, Count, i){
'i = value for alpha.'
# Update
list.node.size[Count]     <<- i
# Train Model
print(paste('Training Model Using Alpha => ', i))
m0 = ranger(duration ~., data = data.train, num.trees = 200, mtry = 10, alpha = 0.1, min.node.size = i)
# Generate OOB RSE
print('Generating OOB RSE')
m0.oob.rse            = round(sqrt(m0$prediction.error),4)
list.oob.rse[Count]   <<- m0.oob.rse
print(paste('OOB RSE => ', m0.oob.rse))
# Generate Prediction Using New Sample Data
print('Generating Test Prediction')
m0.predict            = predict(m0, data.test)
# Calculate Test RSE
print('Generating Test RSE')
m0.test.rse           = round(sqrt(sum((data.test$duration - m0.predict$predictions)^2) / (length(m0.predict$predictions)-2)),4)
list.test.rse[Count]  <<- m0.test.rse
print(paste('Test RSE =>', m0.test.rse))
# Increase Count
Count                 <<- Count + 1
# Return Model
print('Model Completed.  Returning model object to user')
print('-----------------------------------------------------------------------------')
}
for (i in seq(1, 100, 20)){
rf_num_trees(s6.250k.wlimits_ran, s1.50k.nolimits, list.nmtry, list.oob.rse, list.test.rse, Count, i)
}
# Test Number of Trees
list.node.size = c()
list.oob.rse = c()
list.test.rse = c()
Count = 1
rf_num_trees = function(data.train, data.test, list.ntrees, list.oob.rse, list.test.rse, Count, i){
'i = value for alpha.'
# Update
list.node.size[Count]     <<- i
# Train Model
print(paste('Training Model Using Min.Node.Size => ', i))
m0 = ranger(duration ~., data = data.train, num.trees = 200, mtry = 10, alpha = 0.1, min.node.size = i)
# Generate OOB RSE
print('Generating OOB RSE')
m0.oob.rse            = round(sqrt(m0$prediction.error),4)
list.oob.rse[Count]   <<- m0.oob.rse
print(paste('OOB RSE => ', m0.oob.rse))
# Generate Prediction Using New Sample Data
print('Generating Test Prediction')
m0.predict            = predict(m0, data.test)
# Calculate Test RSE
print('Generating Test RSE')
m0.test.rse           = round(sqrt(sum((data.test$duration - m0.predict$predictions)^2) / (length(m0.predict$predictions)-2)),4)
list.test.rse[Count]  <<- m0.test.rse
print(paste('Test RSE =>', m0.test.rse))
# Increase Count
Count                 <<- Count + 1
# Return Model
print('Model Completed.  Returning model object to user')
print('-----------------------------------------------------------------------------')
}
# Iterate over number of mtry
for (i in seq(1, 10, 1)){
rf_num_trees(s6.250k.wlimits_ran, s1.50k.nolimits, list.nmtry, list.oob.rse, list.test.rse, Count, i)
}
#Create DataFrame
df = data.frame(row.names = list.alpha)
df$oob.rse     = list.oob.rse
df$test.rse    = list.test.rse
list.oob.rse
# Graph Results
p = ggplot() +
geom_line(data = df, aes(x = list.alpha, y = df$oob.rse, color = 'OOB RSE')) +
geom_line(data = df, aes(x = list.alpha, y = df$test.rse, color = 'Test RSE')) +
xlab('MIN.NODE.SIZE') +
ylab('RSE')
print(p+ ggtitle('RANDOM FOREST - TRAINING & TEST RSE'))
df = data.frame(row.names = list.alpha)
df$oob.rse     = list.oob.rse
df$test.rse    = list.test.rse
list.oob.rse
p = ggplot() +
geom_line(data = df, aes(x = list.alpha, y = df$oob.rse, color = 'OOB RSE')) +
geom_line(data = df, aes(x = list.alpha, y = df$test.rse, color = 'Test RSE')) +
xlab('MIN.NODE.SIZE') +
ylab('RSE')
print(p+ ggtitle('RANDOM FOREST - TRAINING & TEST RSE'))
print(p)
df$test.rse    = list.test.rse
#Create DataFrame
df = data.frame(row.names = list.node.size)
df$oob.rse     = list.oob.rse
df$test.rse    = list.test.rse
list.oob.rse
p = ggplot() +
geom_line(data = df, aes(x = list.alpha, y = df$oob.rse, color = 'OOB RSE')) +
geom_line(data = df, aes(x = list.alpha, y = df$test.rse, color = 'Test RSE')) +
xlab('MIN.NODE.SIZE') +
ylab('RSE')
print(p+ ggtitle('RANDOM FOREST - TRAINING & TEST RSE'))
p = ggplot() +
geom_line(data = df, aes(x = list.node.size, y = df$oob.rse, color = 'OOB RSE')) +
geom_line(data = df, aes(x = list.node.size, y = df$test.rse, color = 'Test RSE')) +
xlab('MIN.NODE.SIZE') +
ylab('RSE')
print(p+ ggtitle('RANDOM FOREST - TRAINING & TEST RSE'))
p = ggplot() +
#  geom_line(data = df, aes(x = list.node.size, y = df$oob.rse, color = 'OOB RSE')) +
geom_line(data = df, aes(x = list.node.size, y = df$test.rse, color = 'Test RSE')) +
xlab('MIN.NODE.SIZE') +
ylab('RSE')
print(p+ ggtitle('RANDOM FOREST - TRAINING & TEST RSE'))
print(p+ ggtitle('RANDOM FOREST - MIN.NODE.SIZE - TEST RSE'))
# M3    HYPER PARAMETER SELECTION - ALPHA______________________________________________
'alpha	For "maxstat" splitrule: Significance threshold to allow splitting.
Default = 0.5
'
# Test Number of Trees
list.alpha = c()
list.oob.rse = c()
list.test.rse = c()
Count = 1
rf_num_trees = function(data.train, data.test, list.ntrees, list.oob.rse, list.test.rse, Count, i){
'i = value for alpha.'
# Update
list.alpha[Count]     <<- i
# Train Model
print(paste('Training Model Using Alpha => ', i))
m0 = ranger(duration ~., data = data.train, num.trees = 200, mtry = 10, alpha = i)
# Generate OOB RSE
print('Generating OOB RSE')
m0.oob.rse            = round(sqrt(m0$prediction.error),4)
list.oob.rse[Count]   <<- m0.oob.rse
print(paste('OOB RSE => ', m0.oob.rse))
# Generate Prediction Using New Sample Data
print('Generating Test Prediction')
m0.predict            = predict(m0, data.test)
# Calculate Test RSE
print('Generating Test RSE')
m0.test.rse           = round(sqrt(sum((data.test$duration - m0.predict$predictions)^2) / (length(m0.predict$predictions)-2)),4)
list.test.rse[Count]  <<- m0.test.rse
print(paste('Test RSE =>', m0.test.rse))
# Increase Count
Count                 <<- Count + 1
# Return Model
print('Model Completed.  Returning model object to user')
print('-----------------------------------------------------------------------------')
}
# Iterate over number of mtry
for (i in seq(0.5, 0.01, -0.2)){
rf_num_trees(s6.250k.wlimits_ran, s1.50k.nolimits, list.nmtry, list.oob.rse, list.test.rse, Count, i)
}
df = data.frame(row.names = list.alpha)
df$oob.rse     = list.oob.rse
df$test.rse    = list.test.rse
p = ggplot() +
#  geom_line(data = df, aes(x = list.alpha, y = df$oob.rse, color = 'OOB RSE')) +
geom_line(data = df, aes(x = list.alpha, y = df$test.rse, color = 'Test RSE')) +
xlab('ALPHA') +
ylab('RSE')
print(p+ ggtitle('RANDOM FOREST - ALPHA - TEST RSE'))
for (i in seq(0.5, 0.001, -0.2)){
rf_num_trees(s6.250k.wlimits_ran, s1.50k.nolimits, list.nmtry, list.oob.rse, list.test.rse, Count, i)
}
for (i in seq(0.5, 0.01, -0.1)){
print(i)
}
for (i in seq(0.5, 0.01, -0.01)){
print(i)
}
for (i in seq(0.5, 0.01, -0.05)){
print(i)
}
for (i in seq(0.5, 0.01, -0.05)){
rf_num_trees(s6.250k.wlimits_ran, s1.50k.nolimits, list.nmtry, list.oob.rse, list.test.rse, Count, i)
}
for (i in seq(0.5, 0.01, -0.05)){
rf_num_trees(s6.250k.wlimits_ran, s1.50k.nolimits, list.nmtry, list.oob.rse, list.test.rse, Count, i)
}
#Create DataFrame
df = data.frame(row.names = list.alpha)
df$oob.rse     = list.oob.rse
df$test.rse    = list.test.rse
list.oob.rse
# Graph Results
p = ggplot() +
#  geom_line(data = df, aes(x = list.alpha, y = df$oob.rse, color = 'OOB RSE')) +
geom_line(data = df, aes(x = list.alpha, y = df$test.rse, color = 'Test RSE')) +
xlab('ALPHA') +
ylab('RSE')
print(p+ ggtitle('RANDOM FOREST - ALPHA - TEST RSE'))
#Create DataFrame
df = data.frame(row.names = list.alpha)
df$oob.rse     = list.oob.rse
df$test.rse    = list.test.rse
# Graph Results
p = ggplot() +
#  geom_line(data = df, aes(x = list.alpha, y = df$oob.rse, color = 'OOB RSE')) +
geom_line(data = df, aes(x = list.alpha, y = df$test.rse, color = 'Test RSE')) +
xlab('ALPHA') +
ylab('RSE')
print(p+ ggtitle('RANDOM FOREST - ALPHA - TEST RSE'))
# RANDOM FOREST_____________________________________________________________________
## CLEAR NAMESPACE________________________________________________________________________
rm(list = ls())
## IMPORT LIBRARIES_______________________________________________________________________
library(ggplot2)
library(randomForest)
library(ranger)               # Faster implementation of Random Forest
library(tree)
library(ISLR)
library(MASS)
library(caret)                # library that contains the train() function
## IMPORT PERSONAL FUNCTIONS_____________________________________________________________
source('/home/ccirelli2/Desktop/Repositories/ML_Final_Project_2019/Gotham_Cabs/code/R/Decision_Tree/module0_random_forest.R')
## CREATE DATASET_________________________________________________________________________
setwd('/home/ccirelli2/Desktop/Repositories/ML_Final_Project_2019/Gotham_Cabs/data')
s1.50k.nolimits        = read.csv('sample1_50k.csv')[2:12]                          #[2:12] drop datetime col.
s2.100k.nolimits       = read.csv('sample1_100k.csv')[2:12]
s3.250k.nolimits       = read.csv('sample1_250k.csv')[2:12]
s4.50k.wlimits         = read.csv('sample2_wlimits_50k.csv')[2:12]
s5.100k.wlimits        = read.csv('sample2_wlimits_100k.csv')[2:12]
s6.250k.wlimits        = read.csv('sample2_wlimits_250k.csv')[2:12]
# RANDOMIZE DATA__________________________________________________________________________
s1.50k.nolimits_ran    = s1.50k.nolimits[sample(nrow(s1.50k.nolimits)),]
s2.100k.nolimits_ran   = s2.100k.nolimits[sample(nrow(s2.100k.nolimits)),]
s3.250k.nolimits_ran   = s3.250k.nolimits[sample(nrow(s3.250k.nolimits)),]
s4.50k.wlimits_ran     = s4.50k.wlimits[sample(nrow(s4.50k.wlimits)), ]
s5.100k.wlimits_ran    = s5.100k.wlimits[sample(nrow(s5.100k.wlimits)), ]
s6.250k.wlimits_ran    = s6.250k.wlimits[sample(nrow(s6.250k.wlimits)), ]
# TRAIN / TEST SPLIT______________________________________________________________________
# Calculate Number of Training Observations
train_nrows_50k  = (nrow(s1.50k.nolimits)  * .7)
train_nrows_100k = (nrow(s2.100k.nolimits)   * .7)
train_nrows_250k = (nrow(s3.250k.nolimits)   * .7)
# Train
s1.train = s1.50k.nolimits_ran[1:   train_nrows_50k, ]
s2.train = s2.100k.nolimits_ran[1:  train_nrows_100k, ]
s3.train = s3.250k.nolimits_ran[1:  train_nrows_250k, ]
s4.train = s4.50k.wlimits_ran[1:    train_nrows_50k, ]
s5.train = s5.100k.wlimits_ran[1:   train_nrows_100k, ]
s6.train = s6.250k.wlimits_ran[1:   train_nrows_250k, ]
# Test
s1.test = s1.50k.nolimits_ran[train_nrows_50k:    nrow(s1.50k.nolimits_ran), ] # Index from training to total
s2.test = s2.100k.nolimits_ran[train_nrows_100k:  nrow(s2.100k.nolimits_ran), ]
s3.test = s3.250k.nolimits_ran[train_nrows_250k:  nrow(s3.250k.nolimits_ran), ]
s4.test = s4.50k.wlimits_ran[train_nrows_50k:     nrow(s4.50k.wlimits_ran), ]
s5.test = s5.100k.wlimits_ran[train_nrows_100k:   nrow(s5.100k.wlimits_ran), ]
s6.test = s6.250k.wlimits_ran[train_nrows_250k:   nrow(s6.250k.wlimits_ran), ]
# Test Number of Trees
list.alpha = c()
list.oob.rse = c()
list.test.rse = c()
Count = 1
rf_num_trees = function(data.train, data.test, list.ntrees, list.oob.rse, list.test.rse, Count, i){
'i = value for alpha.'
# Update
list.alpha[Count]     <<- i
# Train Model
print(paste('Training Model Using Alpha => ', i))
m0 = ranger(duration ~., data = data.train, num.trees = 200, mtry = 10, alpha = i)
# Generate OOB RSE
print('Generating OOB RSE')
m0.oob.rse            = round(sqrt(m0$prediction.error),4)
list.oob.rse[Count]   <<- m0.oob.rse
print(paste('OOB RSE => ', m0.oob.rse))
# Generate Prediction Using New Sample Data
print('Generating Test Prediction')
m0.predict            = predict(m0, data.test)
# Calculate Test RSE
print('Generating Test RSE')
m0.test.rse           = round(sqrt(sum((data.test$duration - m0.predict$predictions)^2) / (length(m0.predict$predictions)-2)),4)
list.test.rse[Count]  <<- m0.test.rse
print(paste('Test RSE =>', m0.test.rse))
# Increase Count
Count                 <<- Count + 1
# Return Model
print('Model Completed.  Returning model object to user')
print('-----------------------------------------------------------------------------')
}
for (i in seq(0.5, 0.01, -0.05)){
rf_num_trees(s6.250k.wlimits_ran, s1.50k.nolimits, list.nmtry, list.oob.rse, list.test.rse, Count, i)
}
list.alpha
#Create DataFrame
df = data.frame(row.names = list.alpha)
df$oob.rse     = list.oob.rse
df$test.rse    = list.test.rse
list.oob.rse
p = ggplot() +
#  geom_line(data = df, aes(x = list.alpha, y = df$oob.rse, color = 'OOB RSE')) +
geom_line(data = df, aes(x = list.alpha, y = df$test.rse, color = 'Test RSE')) +
xlab('ALPHA') +
ylab('RSE')
print(p+ ggtitle('RANDOM FOREST - ALPHA - TEST RSE'))
list.node.size = c()
list.oob.rse = c()
list.test.rse = c()
Count = 1
rf_num_trees = function(data.train, data.test, list.ntrees, list.oob.rse, list.test.rse, Count, i){
'i = value for alpha.'
# Update
list.node.size[Count]     <<- i
# Train Model
print(paste('Training Model Using Min.Node.Size => ', i))
m0 = ranger(duration ~., data = data.train, num.trees = 200, mtry = 10, alpha = 0.1, min.node.size = i)
# Generate OOB RSE
print('Generating OOB RSE')
m0.oob.rse            = round(sqrt(m0$prediction.error),4)
list.oob.rse[Count]   <<- m0.oob.rse
print(paste('OOB RSE => ', m0.oob.rse))
# Generate Prediction Using New Sample Data
print('Generating Test Prediction')
m0.predict            = predict(m0, data.test)
# Calculate Test RSE
print('Generating Test RSE')
m0.test.rse           = round(sqrt(sum((data.test$duration - m0.predict$predictions)^2) / (length(m0.predict$predictions)-2)),4)
list.test.rse[Count]  <<- m0.test.rse
print(paste('Test RSE =>', m0.test.rse))
# Increase Count
Count                 <<- Count + 1
# Return Model
print('Model Completed.  Returning model object to user')
print('-----------------------------------------------------------------------------')
}
rf_num_trees = function(data.train, data.test, list.ntrees, list.oob.rse, list.test.rse, Count, i){
'i = value for alpha.'
# Update
list.node.size[Count]     <<- i
# Train Model
print(paste('Training Model Using Min.Node.Size => ', i))
m0 = ranger(duration ~., data = data.train, num.trees = 200, mtry = 10, alpha = 0.1, min.node.size = i)
# Generate OOB RSE
print('Generating OOB RSE')
m0.oob.rse            = round(sqrt(m0$prediction.error),4)
list.oob.rse[Count]   <<- m0.oob.rse
print(paste('OOB RSE => ', m0.oob.rse))
# Generate Prediction Using New Sample Data
print('Generating Test Prediction')
m0.predict            = predict(m0, data.test)
# Calculate Test RSE
print('Generating Test RSE')
m0.test.rse           = round(sqrt(sum((data.test$duration - m0.predict$predictions)^2) / (length(m0.predict$predictions)-2)),4)
list.test.rse[Count]  <<- m0.test.rse
print(paste('Test RSE =>', m0.test.rse))
# Increase Count
Count                 <<- Count + 1
# Return Model
print('Model Completed.  Returning model object to user')
print('-----------------------------------------------------------------------------')
}
for (i in seq(1, 10, 1)){
rf_num_trees(s6.250k.wlimits_ran, s1.50k.nolimits, list.nmtry, list.oob.rse, list.test.rse, Count, i)
}
## CLEAR NAMESPACE________________________________________________________________________
rm(list = ls())
## IMPORT LIBRARIES_______________________________________________________________________
library(ggplot2)
library(randomForest)
library(ranger)               # Faster implementation of Random Forest
library(tree)
library(ISLR)
library(MASS)
library(caret)                # library that contains the train() function
setwd('/home/ccirelli2/Desktop/Repositories/ML_Final_Project_2019/Gotham_Cabs/data')
s1.50k.nolimits        = read.csv('sample1_50k.csv')[2:12]                          #[2:12] drop datetime col.
s2.100k.nolimits       = read.csv('sample1_100k.csv')[2:12]
s3.250k.nolimits       = read.csv('sample1_250k.csv')[2:12]
s4.50k.wlimits         = read.csv('sample2_wlimits_50k.csv')[2:12]
s5.100k.wlimits        = read.csv('sample2_wlimits_100k.csv')[2:12]
s6.250k.wlimits        = read.csv('sample2_wlimits_250k.csv')[2:12]
# RANDOMIZE DATA__________________________________________________________________________
s1.50k.nolimits_ran    = s1.50k.nolimits[sample(nrow(s1.50k.nolimits)),]
s2.100k.nolimits_ran   = s2.100k.nolimits[sample(nrow(s2.100k.nolimits)),]
s3.250k.nolimits_ran   = s3.250k.nolimits[sample(nrow(s3.250k.nolimits)),]
s4.50k.wlimits_ran     = s4.50k.wlimits[sample(nrow(s4.50k.wlimits)), ]
s5.100k.wlimits_ran    = s5.100k.wlimits[sample(nrow(s5.100k.wlimits)), ]
s6.250k.wlimits_ran    = s6.250k.wlimits[sample(nrow(s6.250k.wlimits)), ]
rm(list = ls())
## IMPORT LIBRARIES_______________________________________________________________________
library(ggplot2)
library(randomForest)
library(ranger)               # Faster implementation of Random Forest
library(tree)
library(ISLR)
library(MASS)
library(caret)                # library that contains the train() function
source('/home/ccirelli2/Desktop/Repositories/ML_Final_Project_2019/Gotham_Cabs/code/R/Decision_Tree/module0_random_forest.R')
## CREATE DATASET_________________________________________________________________________
setwd('/home/ccirelli2/Desktop/Repositories/ML_Final_Project_2019/Gotham_Cabs/data')
s1.50k.nolimits        = read.csv('sample1_50k.csv')[2:12]                          #[2:12] drop datetime col.
s2.100k.nolimits       = read.csv('sample1_100k.csv')[2:12]
s3.250k.nolimits       = read.csv('sample1_250k.csv')[2:12]
s4.50k.wlimits         = read.csv('sample2_wlimits_50k.csv')[2:12]
s5.100k.wlimits        = read.csv('sample2_wlimits_100k.csv')[2:12]
s6.250k.wlimits        = read.csv('sample2_wlimits_250k.csv')[2:12]
# RANDOMIZE DATA__________________________________________________________________________
s1.50k.nolimits_ran    = s1.50k.nolimits[sample(nrow(s1.50k.nolimits)),]
s2.100k.nolimits_ran   = s2.100k.nolimits[sample(nrow(s2.100k.nolimits)),]
s3.250k.nolimits_ran   = s3.250k.nolimits[sample(nrow(s3.250k.nolimits)),]
s4.50k.wlimits_ran     = s4.50k.wlimits[sample(nrow(s4.50k.wlimits)), ]
s5.100k.wlimits_ran    = s5.100k.wlimits[sample(nrow(s5.100k.wlimits)), ]
s6.250k.wlimits_ran    = s6.250k.wlimits[sample(nrow(s6.250k.wlimits)), ]
# Calculate Number of Training Observations
train_nrows_50k  = (nrow(s1.50k.nolimits)  * .7)
train_nrows_100k = (nrow(s2.100k.nolimits)   * .7)
train_nrows_250k = (nrow(s3.250k.nolimits)   * .7)
# Train
s1.train = s1.50k.nolimits_ran[1:   train_nrows_50k, ]
s2.train = s2.100k.nolimits_ran[1:  train_nrows_100k, ]
s3.train = s3.250k.nolimits_ran[1:  train_nrows_250k, ]
s4.train = s4.50k.wlimits_ran[1:    train_nrows_50k, ]
s5.train = s5.100k.wlimits_ran[1:   train_nrows_100k, ]
s6.train = s6.250k.wlimits_ran[1:   train_nrows_250k, ]
# Test
s1.test = s1.50k.nolimits_ran[train_nrows_50k:    nrow(s1.50k.nolimits_ran), ] # Index from training to total
s2.test = s2.100k.nolimits_ran[train_nrows_100k:  nrow(s2.100k.nolimits_ran), ]
s3.test = s3.250k.nolimits_ran[train_nrows_250k:  nrow(s3.250k.nolimits_ran), ]
s4.test = s4.50k.wlimits_ran[train_nrows_50k:     nrow(s4.50k.wlimits_ran), ]
s5.test = s5.100k.wlimits_ran[train_nrows_100k:   nrow(s5.100k.wlimits_ran), ]
s6.test = s6.250k.wlimits_ran[train_nrows_250k:   nrow(s6.250k.wlimits_ran), ]
# Test Number of Trees
list.node.size = c()
list.oob.rse = c()
list.test.rse = c()
Count = 1
rf_num_trees = function(data.train, data.test, list.ntrees, list.oob.rse, list.test.rse, Count, i){
'i = value for alpha.'
# Update
list.node.size[Count]     <<- i
# Train Model
print(paste('Training Model Using Min.Node.Size => ', i))
m0 = ranger(speed ~., data = data.train, num.trees = 200, mtry = 10, alpha = 0.1, min.node.size = i)
# Generate OOB RSE
print('Generating OOB RSE')
m0.oob.rse            = round(sqrt(m0$prediction.error),4)
list.oob.rse[Count]   <<- m0.oob.rse
print(paste('OOB RSE => ', m0.oob.rse))
# Generate Prediction Using New Sample Data
print('Generating Test Prediction')
m0.predict            = predict(m0, data.test)
# Calculate Test RSE
print('Generating Test RSE')
m0.test.rse           = round(sqrt(sum((data.test$duration - m0.predict$predictions)^2) / (length(m0.predict$predictions)-2)),4)
list.test.rse[Count]  <<- m0.test.rse
print(paste('Test RSE =>', m0.test.rse))
# Increase Count
Count                 <<- Count + 1
# Return Model
print('Model Completed.  Returning model object to user')
print('-----------------------------------------------------------------------------')
rf_num_trees = function(data.train, data.test, list.ntrees, list.oob.rse, list.test.rse, Count, i){
'i = value for alpha.'
# Update
list.node.size[Count]     <<- i
# Train Model
print(paste('Training Model Using Min.Node.Size => ', i))
m0 = ranger(speed ~., data = data.train, num.trees = 200, mtry = 10, alpha = 0.1, min.node.size = i)
# Generate OOB RSE
print('Generating OOB RSE')
m0.oob.rse            = round(sqrt(m0$prediction.error),4)
list.oob.rse[Count]   <<- m0.oob.rse
print(paste('OOB RSE => ', m0.oob.rse))
# Generate Prediction Using New Sample Data
print('Generating Test Prediction')
m0.predict            = predict(m0, data.test)
# Calculate Test RSE
print('Generating Test RSE')
m0.test.rse           = round(sqrt(sum((data.test$duration - m0.predict$predictions)^2) / (length(m0.predict$predictions)-2)),4)
list.test.rse[Count]  <<- m0.test.rse
print(paste('Test RSE =>', m0.test.rse))
# Increase Count
Count                 <<- Count + 1
# Return Model
print('Model Completed.  Returning model object to user')
print('-----------------------------------------------------------------------------')
}
df = data.frame(row.names = list.node.size)
df$oob.rse     = list.oob.rse
df$test.rse    = list.test.rse
list.oob.rse
m0 = ranger(speed ~., data = data.train, num.trees = 200, mtry = 10, alpha = 0.1, min.node.size = 5)
print('hello world')
