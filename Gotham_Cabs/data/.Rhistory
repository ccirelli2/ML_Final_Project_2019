data_ctrl = trainControl(method = 'cv', number = 10, verboseIter = TRUE)
# Step2:  Fit Model and pass control parameters to model
lr.m1.cv =        train(num ~ age + sex + cp + trestbps + chol + fbs + restecg + thalach + exang + oldpeak + slope + ca + thal, # model to fit
data = data.cat,                                                       # data
method = 'lda',                                                        # general linear model
family = 'binomial',                                                   # binomial for logistic regression
trControl = data_ctrl                                                  # pass training control parameters.
)
# Step2:  Fit Model and pass control parameters to model
lda.m1.cv =        train(num ~ age + sex + cp + trestbps + chol + fbs + restecg + thalach + exang + oldpeak + slope + ca + thal, # model to fit
data = data.cat,                                                       # data
method = 'lda',                                                        # general linear model
family = 'binomial',                                                   # binomial for logistic regression
trControl = data_ctrl                                                  # pass training control parameters.
)
lda.m1.cv
# Step2:  Fit Model and pass control parameters to model
lda.m1.cv =        train(num ~ age + sex + cp + trestbps + chol + fbs + restecg + thalach + exang + oldpeak + slope + ca + thal, # model to fit
data = data.cat,                                                       # data
method = 'lda',                                                        # general linear model
trControl = data_ctrl                                                  # pass training control parameters.
)
lda.m1.cv
# Step2:  Fit Model and pass control parameters to model
lda.m1.cv =        train(num ~ age + sex + cp + trestbps + chol + fbs + restecg + thalach + exang + oldpeak + slope + ca + thal, # model to fit
data = data.cat,                                                       # data
method = 'nd',                                                        # general linear model
trControl = data_ctrl                                                  # pass training control parameters.
)
# Step1:  Set up training control
data_ctrl = trainControl(method = 'boot', number = 10, verboseIter = TRUE)
# Step2:  Fit Model and pass control parameters to model
lda.m1.cv =        train(num ~ age + sex + cp + trestbps + chol + fbs + restecg + thalach + exang + oldpeak + slope + ca + thal, # model to fit
data = data.cat,                                                       # data
method = 'lda',                                                        # general linear model
trControl = data_ctrl                                                  # pass training control parameters.
)
# Step1:  Set up training control
data_ctrl = trainControl(method = 'cv', number = 10, verboseIter = TRUE)
library('lda')
library(lda)
library(MASS)
# Step2:  Fit Model and pass control parameters to model
lda.m1.cv =        train(num ~ age + sex + cp + trestbps + chol + fbs + restecg + thalach + exang + oldpeak + slope + ca + thal, # model to fit
data = data.cat,                                                       # data
method = 'lda',                                                        # general linear model
trControl = data_ctrl                                                  # pass training control parameters.
)
# Step2:  Fit Model and pass control parameters to model
lda.m1.cv =        train(num ~ age + sex + cp + trestbps + chol + fbs + restecg + thalach + exang + oldpeak + slope + ca + thal, # model to fit
data = data.cat,                                                       # data
method = 'lda',                                                        # general linear model
trControl = trainControl('cv')                                                  # pass training control parameters.
)
lda.m1.cv.fit
library(caret)
library('mlbench')
library(mlbench)
install.packages("mlbench")
mlbench
library(mlbench)
# Step1:  Set up training control
kfoldcv = trainControl(method="cv", number=10)
performance_metric = 'Accuracy'
lda.data = train(train(num ~., data=hr_data, method="lda", metric=performance_metric trControl=kfoldcv)
lda.data = train(train(num ~., data=hr_data, method="lda", metric=performance_metric, trControl = kfoldcv)
lda.data = train(num ~., data=hr_data, method="lda", metric=performance_metric, trControl = kfoldcv)
lda.data = train(num~., data=hr_data, method="lda", metric=performance_metric, trControl = kfoldcv)
data_ctrl = trainControl(method = 'cv', number = 10, verboseIter = TRUE)
lda.m1.cv =        train(num ~., # model to fit
data = data.cat,                                                       # data
method = 'lda',                                                        # general linear model
family = 'binomial',                                                   # binomial for logistic regression
trControl = data_ctrl                                                  # pass training control parameters.
)
lda.m1.cv =        train(num ~., # model to fit
data = data.cat,                                                       # data
method = 'lda',                                                        # general linear model
family = 'binomial',                                                   # binomial for logistic regression
trControl = data_ctrl                                                  # pass training control parameters.
)
lda.m1.cv =        train(num ~., # model to fit
data = data.cat,                                                       # data
method = 'glm',                                                        # general linear model
family = 'binomial',                                                   # binomial for logistic regression
trControl = data_ctrl                                                  # pass training control parameters.
)
lda.m1.cv =        train(num ~., # model to fit
data = data.cat,                                                       # data
method = 'glm',                                                        # general linear model
family = 'binomial',                                                   # binomial for logistic regression
trControl = data_ctrl                                                  # pass training control parameters.
)
lda.m1.cv =        train(num ~., # model to fit
data = data.cat,                                                       # data
method = 'qda',                                                        # general linear model
family = 'binomial',                                                   # binomial for logistic regression
trControl = data_ctrl                                                  # pass training control parameters.
)
data_ctrl = trainControl(method = 'cv', number = 10, classProbs = TRUE, summaryFunction = twoClassSummary)
lda.m1.cv =        train(data.cat,
# data
method = 'lda',                                                        # general linear model
family = 'binomial',                                                   # binomial for logistic regression
trControl = data_ctrl                                                  # pass training control parameters.
)
lda.m1.cv =        train(data.cat,
# data
method = 'lda',                                                        # general linear model
# binomial for logistic regression
trControl = data_ctrl                                                  # pass training control parameters.
)
x = data.cat[:, -data.cat$num]
x = data.cat[0:length(data.cat$age), -data.cat$num]
head(x)
x = data.cat[0:length(data.cat$age), 0:13]
head(x)
lda.m1.cv =        train(x, y
method = 'lda',                                                        # general linear model
trControl = data_ctrl,                                                  # pass training control parameters.
metric = 'Accuracy'
)
lda.m1.cv =        train(x, y,
method = 'lda',                                                        # general linear model
trControl = data_ctrl,                                                  # pass training control parameters.
metric = 'Accuracy'
)
y = data.cat$num
lda.m1.cv =        train(x, y,
method = 'lda',                                                        # general linear model
trControl = data_ctrl,                                                  # pass training control parameters.
metric = 'Accuracy'
)
x = hr_data[0:length(data.cat$age), 0:13]
y = hr_data$num
lda.m1.cv =        train(x, y,
method = 'lda',                                                        # general linear model
trControl = data_ctrl,                                                  # pass training control parameters.
metric = 'Accuracy'
)
data_ctrl = trainControl(method = 'cv', number = 10, verboseIter = TRUE)
data.cat$num
lda.m1.cv =        train(num ~., # model to fit
data = data.cat,                                                       # data
method = 'lda',                                                        # general linear model
family = 'binomial',                                                   # binomial for logistic regression
trControl = data_ctrl                                                  # pass training control parameters.
)
lda.m1.cv =        train(num ~., # model to fit
data = data.cat,                                                       # data
method = 'qda',                                                        # general linear model
family = 'binomial',                                                   # binomial for logistic regression
trControl = data_ctrl                                                  # pass training control parameters.
)
data.cat$num         = factor(data.cat$num)
data_ctrl = trainControl(method = 'cv', number = 10, verboseIter = TRUE)
lda.m1.cv =        train(num ~., # model to fit
data = data.cat,                                                       # data
method = 'lda',                                                        # general linear model
family = 'binomial',                                                   # binomial for logistic regression
trControl = data_ctrl                                                  # pass training control parameters.
)
data_ctrl = trainControl(method = 'cv', number = 10, verboseIter = TRUE)
lda.m1.cv =        train(num ~., # model to fit
data = data.cat,                                                       # data
method = 'qda',                                                        # general linear model
family = 'binomial',                                                   # binomial for logistic regression
trControl = data_ctrl                                                  # pass training control parameters.
)
# Step4:  Investigate Final Model
lr.m1.cv$finalModel
lda.m1.cv$resample$Accuracy
lda.m1.cv$resample$Accuracy
# Step5:  Examine Model Predictions (R2) For Each Fold
lr.m1.cv$Resample
# Step5:  Examine Model Predictions (R2) For Each Fold
lr.m1.cv$results
lda.m1.cv$results
lqa.m1.cv =        train(num ~., # model to fit
data = data.cat,                                                       # data
method = 'qda',                                                        # general linear model
family = 'binomial',                                                   # binomial for logistic regression
trControl = data_ctrl                                                  # pass training control parameters.
)
qda.m1.cv =        train(num ~., # model to fit
data = data.cat,                                                       # data
method = 'qda',                                                        # general linear model
family = 'binomial',                                                   # binomial for logistic regression
trControl = data_ctrl                                                  # pass training control parameters.
)
lr.m1.cv$results
lda.m1.cv$results
qda.m1.cv$results
# Step1:  Set up training control
data_ctrl = trainControl(method = 'cv', number = 10, verboseIter = TRUE, metric = "Accuracy")
data_ctrl_loocv = trainControl(method = 'LOOCV', number = 10, verboseIter = TRUE)
lr.m1.cv.loocv = train(num ~ age + sex + cp + trestbps + chol + fbs + restecg + thalach + exang + oldpeak + slope + ca + thal, # model to fit
data = data.cat,                                                       # data
method = 'glm',                                                        # general linear model
family = 'binomial',                                                   # binomial for logistic regression
trControl = data_ctrl_loocv                                                  # pass training control parameters.
)
lr.m1.cv.loocv
lda.m1.cv =        train(num ~., # model to fit
data = data.cat,                                                       # data
method = 'lda',                                                        # general linear model
family = 'binomial',                                                   # binomial for logistic regression
trControl = data_ctrl_loocv                                                  # pass training control parameters.
)
lda.m1.cv.loocv =        train(num ~., # model to fit
data = data.cat,                                                       # data
method = 'lda',                                                        # general linear model
family = 'binomial',                                                   # binomial for logistic regression
trControl = data_ctrl_loocv                                                  # pass training control parameters.
)
lda.m1.cv.loocv
qda.m1.cv,loocv =        train(num ~., # model to fit
data = data.cat,                                                       # data
method = 'qda',                                                        # general linear model
family = 'binomial',                                                   # binomial for logistic regression
trControl = data_ctrl_loocv                                                  # pass training control parameters.
)
qda.m1.cv.loocv =        train(num ~., # model to fit
data = data.cat,                                                       # data
method = 'qda',                                                        # general linear model
family = 'binomial',                                                   # binomial for logistic regression
trControl = data_ctrl_loocv                                                  # pass training control parameters.
)
qda.m1.cv.loocv
# Clean Namespace
rm(list = ls())
# LOAD LIBRARIES
library(RMySQL)
# CLEAR NAMESPACE
rm(list = ls())
# LOAD LIBRARIES
library(RMySQL)
# SETUP CONNECTION TO DB
mydb <- dbConnect(RMySQL::MySQL(), user='ccirelli2',
password='Work4starr', dbname='GSU',
host = "127.0.0.1")
# Get List of Tables
dbListTables(mydb)
query1_alldata = dbSendQuery(mydb, '
SELECT
MONTH(pickup_datetime) AS "MONTH",
DAY(pickup_datetime) AS "DAY",
pickup_x,
pickup_y,
dropoff_x,
dropoff_y,
duration
FROM ML_FinProj_GothamCab_Train
WHERE duration != 0
LIMIT 1000')
result_q1 = fetch(query1_alldata, n = -1)
# Query 2:  Average Duration By Month
query2_rel_month_duration = dbSendQuery(mydb, '
SELECT
MONTH(pickup_datetime) AS "MONTH",
ROUND(AVG(duration),0) AS "AVERAGE_DURATION"
FROM GSU.ML_FinProj_GothamCab_Train
GROUP BY MONTH(pickup_datetime)
ORDER BY ROUND(AVG(duration),0);')
result_q2 = fetch(query2_rel_month_duration, n = -1)
barplot(data_q2$AVERAGE_DURATION, names.arg = data_q2$MONTH,
main = "Avg Duration By Month",
xlab = "Month",
ylab = "Duration")
barplot(data_q2$AVERAGE_DURATION, names.arg = result_q2$MONTH,
main = "Avg Duration By Month",
xlab = "Month",
ylab = "Duration")
barplot(result_q2$AVERAGE_DURATION, names.arg = result_q2$MONTH,
main = "Avg Duration By Month",
xlab = "Month",
ylab = "Duration")
# Query 3 - Relationship of Average Duration By Day of Week
query3_rel_day_duration = dbSendQuery(mydb, '
SELECT
DAY(pickup_datetime) AS "DAY",
ROUND(AVG(duration),0) AS "AVERAGE_DURATION"
FROM GSU.ML_FinProj_GothamCab_Train
GROUP BY DAY(pickup_datetime)
ORDER BY DAY(pickup_datetime);')
result_q3 = fetch(query3_rel_day_duration, n = -1)
barplot(result_q3$AVERAGE_DURATION,
names.arg = result_q3$DAY,
main = "Average Duration By Day Of Week",
xlab = "Day",
ylab = "Duration")
test_date = 2012-02-01
test_date = weekdays(as.Date(2012-02-01))
test_date = weekdays(as.Date('2012-02-01'))
test_date
test_date = weekdays(as.Date('2034-01-01'))
test_date
query4_rel_weekday_duration = dbSendQuery(mydb, '
SELECT
Weekday,
ROUND(AVG(duration),0) AS "AVERAGE_DURATION"
FROM GSU.ML_FinProj_GothamCab_Train
GROUP BY Weekday
ORDER BY DAY(pickup_datetime);')
query4_rel_weekday_duration = dbSendQuery(mydb, '
SELECT
Weekday,
ROUND(AVG(duration),0) AS "AVERAGE_DURATION"
FROM GSU.ML_FinProj_GothamCab_Train
GROUP BY Weekday
ORDER BY Weekday;')
result_q4 = fetch(query4_rel_weekday_duration, n = -1)
barplot(result_q3$AVERAGE_DURATION,
names.arg = result_q3$DAY,
main = "Average Duration By Weekday",
xlab = "Weekday",
ylab = "Duration")
barplot(result_q4$AVERAGE_DURATION,
names.arg = result_q4$Weekday,
main = "Average Duration By Weekday",
xlab = "Weekday",
ylab = "Duration")
print(result_q4.head())
print(result_q4)
boxplot(result_q4)
boxplot(result_q1$duration)
result_q1$duration
plot(result_q1$duration)
boxplot(result_q1$duration)
histogram(result_q1$duration)
hist(result_q1$duration)
density(result_q1$duration)
d = density(result_q1$duration)
plot(d)
query5_rel_route_duration = dbSendQuery(mydb, '
SELECT
pickup_x,
pickup_y,
dropoff_x,
dropoff_y,
COUNT(duration) AS "Route Count"
FROM GSU.ML_FinProj_GothamCab_Train
GROUP BY pickup_x, pickup_y, dropoff_x, dropoff_y
ORDER BY COUNT(duration) DESC'
)
# Plot Durations
plot(result_q1$duration)
boxplot(result_q1$duration)
hist(result_q1$duration)
d = density(result_q1$duration)
plot(d)
## CLEAR NAMESPACE________________________________________________________________________
rm(list = ls())
## IMPORT LIBRARIES_______________________________________________________________________
library(rpart)
library(rpart.plot)
library(tree)
library(ggplot2)
## CREATE DATASET_________________________________________________________________________
setwd('/home/ccirelli2/Desktop/Repositories/ML_Final_Project_2019/Gotham_Cabs/data')
s1.50k.nolimits        = read.csv('sample1_50k.csv')[2:12]                          #[2:12] drop datetime col.
s2.100k.nolimits       = read.csv('sample1_100k.csv')[2:12]
s3.250k.nolimits       = read.csv('sample1_250k.csv')[2:12]
s4.50k.wlimits         = read.csv('sample2_wlimits_50k.csv')[2:12]
s5.100k.wlimits        = read.csv('sample2_wlimits_100k.csv')[2:12]
s6.250k.wlimits        = read.csv('sample2_wlimits_250k.csv')[2:12]
# RANDOMIZE DATA__________________________________________________________________________
s1.50k.nolimits_ran    = s1.50k.nolimits[sample(nrow(s1.50k.nolimits)),]
s2.100k.nolimits_ran   = s2.100k.nolimits[sample(nrow(s2.100k.nolimits)),]
s3.250k.nolimits_ran   = s3.250k.nolimits[sample(nrow(s3.250k.nolimits)),]
s4.50k.wlimits_ran     = s4.50k.wlimits[sample(nrow(s4.50k.wlimits)), ]
s5.100k.wlimits_ran    = s5.100k.wlimits[sample(nrow(s5.100k.wlimits)), ]
s6.250k.wlimits_ran    = s6.250k.wlimits[sample(nrow(s6.250k.wlimits)), ]
# TRAIN / TEST SPLIT______________________________________________________________________
# Calculate Number of Training Observations
train_nrows_50k  = (nrow(s1.50k.nolimits)  * .7)
train_nrows_100k = (nrow(s2.100k.nolimits)   * .7)
train_nrows_250k = (nrow(s3.250k.nolimits)   * .7)
# Train
s1.train = s1.50k.nolimits_ran[1:   train_nrows_50k, ]
s2.train = s2.100k.nolimits_ran[1:  train_nrows_100k, ]
s3.train = s3.250k.nolimits_ran[1:  train_nrows_250k, ]
s4.train = s4.50k.wlimits_ran[1:    train_nrows_50k, ]
s5.train = s5.100k.wlimits_ran[1:   train_nrows_100k, ]
s6.train = s6.250k.wlimits_ran[1:   train_nrows_250k, ]
# Test
s1.test = s1.50k.nolimits_ran[train_nrows_50k:    nrow(s1.50k.nolimits_ran), ] # Index from training to total
s2.test = s2.100k.nolimits_ran[train_nrows_100k:  nrow(s2.100k.nolimits_ran), ]
s3.test = s3.250k.nolimits_ran[train_nrows_250k:  nrow(s3.250k.nolimits_ran), ]
s4.test = s4.50k.wlimits_ran[train_nrows_50k:     nrow(s4.50k.wlimits_ran), ]
s5.test = s5.100k.wlimits_ran[train_nrows_100k:   nrow(s5.100k.wlimits_ran), ]
s6.test = s6.250k.wlimits_ran[train_nrows_250k:   nrow(s6.250k.wlimits_ran), ]
m1.train = rpart(duration ~ ., data = s1.train, method = 'anova')
rpart.plot(m1.train, type = 3, extra = 101, fallen.leaves = T, main = 'Regression Tree - M1')
# Model1 - Calculate Train RSE
m1.residuals = residuals(m1.train)
m1.train.rse = sqrt(sum(m1.residuals^2) / (length(m1.residuals) - 2))
# Model1 - Generate a Prediction
m1.predict   = predict(m1.train, s1.test)
# Model1 - Calculate Test RSE
m1.test.rse  = sqrt(sum((s1.test$duration - m1.predict)^2) / (length(s1.test$duration) - 2))
m1.test.rse
m1.train = rpart(duration ~ ., data = s6.train, method = 'anova')
rpart.plot(m1.train, type = 3, extra = 101, fallen.leaves = T, main = 'Regression Tree - M1')
# Model1 - Calculate Train RSE
m1.residuals = residuals(m1.train)
m1.train.rse = sqrt(sum(m1.residuals^2) / (length(m1.residuals) - 2))
# Model1 - Generate a Prediction
m1.predict   = predict(m1.train, s1.test)
# Model1 - Calculate Test RSE
m1.test.rse  = sqrt(sum((s1.test$duration - m1.predict)^2) / (length(s1.test$duration) - 2))
m1.test.rse
# Train Model
m2.train = rpart(duration ~ ., data = s6.train, method = 'anova',
control = rpart.control(cp = .0016, minsplit = 5, minbucket = 5, maxdepth = 10))
# Plot Tree
rpart.plot(m2.train, type = 3, extra = 101, fallen.leaves = T, main = 'Regression Tree - M2')
# Calculate Test Residual
m2.residuals = residuals(m2.train)
m2.train.rse = sqrt(sum(m2.residuals^2) / (length(m2.residuals) - 2))
print(paste('Train MSE =>', round(m2.train.rse, 4)))
# Print Results of Cross Validation
printcp(m2.train)
# Plot Cp - Will Plot Number of Splits vs Cp vs Error
plotcp(m2.train)
# Prune Tree
m2.prune = prune(m2.train, cp = 0.001)
rpart.plot(m2.prune, cex = .5, extra = 1)
# Make a Prediction
m2.prune.predict = predict(m2.prune, s6.test)
m2.prune.test.rse = sqrt(sum((s6.test$duration - m2.prune.predict)^2) / (length(s6.test$duration) -2) )
print(paste('Model-2 test rse =>', m2.prune.test.rse))
print(paste('Train MSE =>', round(m2.train.rse, 4)))
# Train Model
m2.train = rpart(duration ~ ., data = s6.train, method = 'anova',
control = rpart.control(cp = .0016, minsplit = 5, minbucket = 5, maxdepth = 5))
# Plot Tree
rpart.plot(m2.train, type = 3, extra = 101, fallen.leaves = T, main = 'Regression Tree - M2')
# Calculate Test Residual
m2.residuals = residuals(m2.train)
m2.train.rse = sqrt(sum(m2.residuals^2) / (length(m2.residuals) - 2))
print(paste('Train MSE =>', round(m2.train.rse, 4)))
m2.train = rpart(duration ~ ., data = s6.train, method = 'anova',
control = rpart.control(cp = .0016, minsplit = 5, minbucket = 5, maxdepth = 3))
# Plot Tree
rpart.plot(m2.train, type = 3, extra = 101, fallen.leaves = T, main = 'Regression Tree - M2')
# Calculate Test Residual
m2.residuals = residuals(m2.train)
m2.train.rse = sqrt(sum(m2.residuals^2) / (length(m2.residuals) - 2))
print(paste('Train MSE =>', round(m2.train.rse, 4)))
# Make Predictin - Unpurned Tree
m2.unpruned.predict = predict(m2.train, s6.test)
m2.unpruned.test.rse = sqrt(sum((s6.test$duration - m2.unpruned.predict)^2) / (length(s6.test$duration) -2) )
print(paste('Model-2 test rse =>', m2.unpruned.test.rse))                  # Pre-pruning test erorr was better.
m2.train = rpart(duration ~ ., data = s6.train, method = 'anova',
control = rpart.control(cp = .0016, minsplit = 5, minbucket = 5, maxdepth = 10))
# Plot Tree
rpart.plot(m2.train, type = 3, extra = 101, fallen.leaves = T, main = 'Regression Tree - M2')
# Calculate Test Residual
m2.residuals = residuals(m2.train)
m2.train.rse = sqrt(sum(m2.residuals^2) / (length(m2.residuals) - 2))
print(paste('Train MSE =>', round(m2.train.rse, 4)))
# Make Predictin - Unpurned Tree
m2.unpruned.predict = predict(m2.train, s6.test)
m2.unpruned.test.rse = sqrt(sum((s6.test$duration - m2.unpruned.predict)^2) / (length(s6.test$duration) -2) )
print(paste('Model-2 test rse =>', round(m2.unpruned.test.rse, 4)))                  # Pre-pruning test erorr was better.
## CLEAR NAMESPACE________________________________________________________________________
rm(list = ls())
## IMPORT LIBRARIES_______________________________________________________________________
library(rpart)
library(rpart.plot)
library(tree)
library(ggplot2)
## CREATE DATASET_________________________________________________________________________
setwd('/home/ccirelli2/Desktop/Repositories/ML_Final_Project_2019/Gotham_Cabs/data')
s1.50k.nolimits        = read.csv('sample1_50k.csv')[2:12]                          #[2:12] drop datetime col.
s2.100k.nolimits       = read.csv('sample1_100k.csv')[2:12]
s3.250k.nolimits       = read.csv('sample1_250k.csv')[2:12]
s4.50k.wlimits         = read.csv('sample2_wlimits_50k.csv')[2:12]
s5.100k.wlimits        = read.csv('sample2_wlimits_100k.csv')[2:12]
s6.250k.wlimits        = read.csv('sample2_wlimits_250k.csv')[2:12]
# RANDOMIZE DATA__________________________________________________________________________
s1.50k.nolimits_ran    = s1.50k.nolimits[sample(nrow(s1.50k.nolimits)),]
s2.100k.nolimits_ran   = s2.100k.nolimits[sample(nrow(s2.100k.nolimits)),]
s3.250k.nolimits_ran   = s3.250k.nolimits[sample(nrow(s3.250k.nolimits)),]
s4.50k.wlimits_ran     = s4.50k.wlimits[sample(nrow(s4.50k.wlimits)), ]
s5.100k.wlimits_ran    = s5.100k.wlimits[sample(nrow(s5.100k.wlimits)), ]
s6.250k.wlimits_ran    = s6.250k.wlimits[sample(nrow(s6.250k.wlimits)), ]
# TRAIN / TEST SPLIT______________________________________________________________________
# Calculate Number of Training Observations
train_nrows_50k  = (nrow(s1.50k.nolimits)  * .7)
train_nrows_100k = (nrow(s2.100k.nolimits)   * .7)
train_nrows_250k = (nrow(s3.250k.nolimits)   * .7)
# Train
s1.train = s1.50k.nolimits_ran[1:   train_nrows_50k, ]
s2.train = s2.100k.nolimits_ran[1:  train_nrows_100k, ]
s3.train = s3.250k.nolimits_ran[1:  train_nrows_250k, ]
s4.train = s4.50k.wlimits_ran[1:    train_nrows_50k, ]
s5.train = s5.100k.wlimits_ran[1:   train_nrows_100k, ]
s6.train = s6.250k.wlimits_ran[1:   train_nrows_250k, ]
# Test
s1.test = s1.50k.nolimits_ran[train_nrows_50k:    nrow(s1.50k.nolimits_ran), ] # Index from training to total
s2.test = s2.100k.nolimits_ran[train_nrows_100k:  nrow(s2.100k.nolimits_ran), ]
s3.test = s3.250k.nolimits_ran[train_nrows_250k:  nrow(s3.250k.nolimits_ran), ]
s4.test = s4.50k.wlimits_ran[train_nrows_50k:     nrow(s4.50k.wlimits_ran), ]
s5.test = s5.100k.wlimits_ran[train_nrows_100k:   nrow(s5.100k.wlimits_ran), ]
s6.test = s6.250k.wlimits_ran[train_nrows_250k:   nrow(s6.250k.wlimits_ran), ]
library(randomForest)
## CLEAR NAMESPACE________________________________________________________________________
rm(list = ls())
install.packages('randomForest')
install.packages("randomForest")
